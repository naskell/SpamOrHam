{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Spam or ham? (45 marks)\n",
    "\n",
    "In the spam literature, an email that is **not** spam is called _ham_. \n",
    "\n",
    "Your task is to develop a Naive Bayes classifier to determine whether a given email is spam or ham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data: Spam!\n",
    "\n",
    "The following cell loads your training data set (called _training set_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam training data set: (1000, 55)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 1. 1. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_spam = np.loadtxt(open(\"data/training_spam.csv\"), delimiter=\",\")\n",
    "print(\"Shape of the spam training data set:\", training_spam.shape)\n",
    "print(training_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your training set consists of 1000 rows and 55 columns. Each row corresponds to one email message. The first column is the _response_ variable and describes whether a message is spam (1) or ham (0). The remaining 54 columns are _features_ that you will use to build a classifier. These features correspond to 54 different keywords (such as \"money\", \"free\", and \"receive\") and special characters (such as \":\", \"!\", and \"$\"). A feature has the value \"1\" if the keyword appears in the message and \"0\" otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model:  Naïve Bayes\n",
    "Your [naïve Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) classifier will distinguish between two classes:\n",
    "\n",
    "* **$C = 1$ for spam messages **\n",
    "* **$C = 0$ for ham messages. **\n",
    "\n",
    "\n",
    "The classifier builds a model for the probability $P(C=c\\ |\\ message)$ that a given message belongs to a certain class. A new message is then classified based on the Bayesian *maximum a posteriori* estimate\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{c} = \\underset{c \\in \\{0,1\\}}{argmax} \\  P(C=c\\ |\\ message).\n",
    "\\end{equation}\n",
    "\n",
    "Using Bayes' rule we can write\n",
    "\n",
    "\\begin{equation}\n",
    "P(C=c\\ |\\ message) = \\frac{P(message\\ |\\ C=c)P(C=c)}{P(message\\ |\\ C=1)P(C=1) + P(message\\ |\\ C=0)P(C=0)}.  \\quad \\quad \n",
    "\\end{equation}\n",
    "\n",
    "The denominator is the same for both classes and we can thus drop it to get\n",
    "\n",
    "\\begin{equation}\n",
    "P(C=c\\ |\\ message) \\propto P(message\\ |\\ C=c)P(C=c).\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "We represent a message using a binary [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) model. Specifically, a message is represented as $\\mathbf{w} = (w_1, ..., w_k)$, where $w_i = 1$ if the word $w_i$ appears in the message and $w_i = 0$ otherwise. We assume **class-conditional independence between occurences of known words** and can therefore write \n",
    "\n",
    "\\begin{equation}\n",
    "P(message\\ |\\ C=c) = \\prod_{i = 1}^k P(w_i\\ |\\ C=c).\n",
    "\\end{equation}\n",
    "\n",
    "The classifier now can be written as follows :\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{c} = \\underset{c \\in \\{0,1\\}}{argmax} \\ [ P(C=c)   \\prod_{i = 1}^k P(w_i\\ |\\ C=c) ].\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "### Multinomial Naïve Bayes\n",
    "\n",
    "Different naïve Bayes models differ in their distributional assumptions of $P(w\\ |\\ C=c)$, that is, the conditional likelihood of a word $w$ given a class $c$. We will model $P(w\\ |\\ C=c)$ using a [multinomial distribution](https://en.wikipedia.org/wiki/Multinomial_distribution). Intuitively, the multinomial distribution assumes that the words of a message are \"drawn\" independently from a bag of $k$ different keywords. Depending on the class membership $c$, each keyword has a probability $\\theta_{class, word}$ of being drawn. For example,\n",
    "\n",
    "* $\\theta_{spam, w}$ will have high value for $w \\in \\{$bank, transfer, buy, viagra... $\\}$.\n",
    "* $\\theta_{ham, w}$ will have high value for $w \\in \\{$paper, conference, proposal, experiment... $\\}$, if the training data was mostly gathered from emails of researchers.\n",
    "\n",
    "Both the class priors $P(C=c)$ and the class-conditional likelihoods $\\theta_{c, w} = P(w\\ |\\ C=c)$ have to be estimated from the training data. The parameters $\\theta_{c, w}$ are estimated by counting the relative frequencies in the training data. Use **Laplace-smoothing** with $\\alpha = 1$, that is,\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta_{c, w} = \\frac{n_{c, w} + \\alpha}{n_{c} + k \\alpha},\n",
    "\\end{equation}\n",
    "\n",
    "where $n_{c, w}$ is the number of times the word $w$ appears in messages of class $c$ in the training set, $n_{c}$ is the total count of words for all messages of class $c$, and $k$ is the number of features (key-words).\n",
    "\n",
    "The likelihood of observing $\\mathbf{w}$ in a message of class $c$ is proportional to\n",
    "\\begin{equation}\n",
    "P(\\mathbf{w}\\ |\\ C=c) \\propto \\prod_{i = 1}^k  (\\theta_{c, i})^{w_i}.\n",
    "\\end{equation}\n",
    "\n",
    "### Increasing numerical stability\n",
    "We can increase the numerical stability of the algorithm by taking logarithms of the posterior distributions, that is,\n",
    "\\begin{equation}\n",
    "\\hat{c} = \\underset{c \\in \\{0,1\\}}{argmax} \\ log( P(C=c)   \\prod_{i = 1}^k P(w_i\\ |\\ C=c) ) \\\\\n",
    " = \\underset{c \\in \\{0,1\\}}{argmax} \\ [ log( P(C=c)) + \\sum_{i = 1}^k w_i \\ log(\\theta_{c, i}) ].\n",
    "\\end{equation}\n",
    "\n",
    "You will implement this more stable version of the algorithm in developing your classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1A: Estimate class priors (10 marks)\n",
    "\n",
    "Define a function called `estimate_log_class_priors()` that takes as input a data set with binary response variable (0s and 1s) in the left-most column and returns a numpy array containing the **the logarithm** of the empirical class priors $P(C=c)$ for $c \\in \\{0, 1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "508e5de25816a015e44a26b186d9ec48",
     "grade": false,
     "grade_id": "cell-f2d751b4a9e29087",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def estimate_log_class_priors(data):\n",
    "    \"\"\"\n",
    "    Given a data set with binary response variable (0s and 1s) in the\n",
    "    left-most column, calculate the logarithm of the empirical class priors,\n",
    "    that is, the logarithm of the proportions of 0s and 1s:\n",
    "    log(P(C=0)) and log(P(C=1))\n",
    "\n",
    "    :param data: a two-dimensional numpy-array with shape = [n_samples, 1 + n_features]\n",
    "                 the first column contains the binary response (coded as 0s and 1s).\n",
    "\n",
    "    :return log_class_priors: a numpy array of length two\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE...\n",
    "    n0 = 0\n",
    "    n1 = 1\n",
    "    log_class_priors = np.zeros(2)\n",
    "    for i in range(data.shape[0]):\n",
    "        if data[i][0] == 0:\n",
    "            n0 += 1.0\n",
    "            #print (n0)\n",
    "        else:\n",
    "            n1 += 1.0 \n",
    "\n",
    "    log0 =  (math.log(n0/1000))\n",
    "    log1 =  (math.log(n1/1000))\n",
    "    log_class_priors[0] = log0\n",
    "    log_class_priors[1] = log1\n",
    "    \n",
    "    return log_class_priors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "94068b6b48e3efb516a1e04893b681c4",
     "grade": true,
     "grade_id": "cell-15a7409a814b361a",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result [-0.48939034 -0.94674994]\n"
     ]
    }
   ],
   "source": [
    "# This is a test cell. Do not delete or change. \n",
    "# You can use this cell to check whether the returned objects of your function are of the right data type.\n",
    "log_class_priors = estimate_log_class_priors(training_spam)\n",
    "print(\"result\", log_class_priors)\n",
    "\n",
    "# Check length\n",
    "assert(len(log_class_priors) == 2)\n",
    "\n",
    "# Check whether the returned object is a numpy.ndarray\n",
    "assert(isinstance(log_class_priors, np.ndarray))\n",
    "\n",
    "# Check wehther the values of this numpy.array are floats.\n",
    "assert(log_class_priors.dtype == float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1B: Estimate class-conditional likelihoods (10 marks)\n",
    "Define a function called `estimate_log_class_conditional_likelihoods()` that takes as input a data set with binary response variable (0s and 1s) in the left-most column and returns **the logarithm** of the empirical class-conditional likelihoods $log(P(w_i | c_j))$ for all words $w_i$ and both classes ($j \\in {0, 1}$). These parameters should be returned in a two-dimensional numpy-array with shape = `[num_classes, num_features]`.\n",
    "\n",
    "Assume a multinomial feature distribution and use Laplace smoothing with $\\alpha = 1$. \n",
    "\n",
    "Hint: many `numpy`-functions contain an `axis` argument. If you specify `axis=0`, you can perform column-wise (that is, feature-wise!) computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cb5d42f2293bb3929365b535540241a6",
     "grade": false,
     "grade_id": "cell-717db5f875274543",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def estimate_log_class_conditional_likelihoods(data, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Given a data set with binary response variable (0s and 1s) in the\n",
    "    left-most column and binary features, calculate the empirical\n",
    "    class-conditional likelihoods, that is,\n",
    "    log(P(w_i | c_j)) for all features i and both classes (j in {0, 1}).\n",
    "\n",
    "    Assume a multinomial feature distribution and use Laplace smoothing\n",
    "    if alpha > 0.\n",
    "\n",
    "    :param data: a two-dimensional numpy-array with shape = [n_samples, n_features]\n",
    "\n",
    "    :return theta:\n",
    "        a numpy array of shape = [2, n_features]. theta[j, i] corresponds to the\n",
    "        logarithm of the probability of feature i appearing in a sample belonging \n",
    "        to class j.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE...\n",
    "    n_features = data.shape[1] - 1\n",
    "    k = n_features\n",
    "    spam_like = [n_features]\n",
    "    ham_like = [n_features]\n",
    "    theta = np.zeros(shape = (2, n_features))\n",
    "    #where  nc,w  is the number of times the word  w  appears in messages of class  \n",
    "    #in the training set,  nc  is the total count of words for all messages of class  \n",
    "    #, and  k  is the number of features (key-words).\n",
    "    # n(c,w) = number of times word w appears in messages of class c in training set\n",
    "    # n(c) = total count of words for all messages of class c\n",
    "    # k = number of features (54)\n",
    "    for i in range (data.shape[0]):\n",
    "        if data[i][0] == 0:\n",
    "            for j in range (0, n_features):\n",
    "                if data[i][j] == 1:\n",
    "                    theta[0][j] += 1\n",
    "        if data[i][0] == 1:\n",
    "            for j in range (0, n_features):\n",
    "                if data[i][j] == 1:\n",
    "                    theta[1][j] += 1\n",
    "\n",
    "    n0 = 0\n",
    "    n1 = 0\n",
    "    for i in range(data.shape[0]):\n",
    "        if data[i][0] == 0:\n",
    "            for j in range (0, n_features):\n",
    "                if data[i][j] == 1:\n",
    "                      n0 += 1     \n",
    "        else:\n",
    "            for j in range (0, n_features):\n",
    "                if data[i][j] == 1:\n",
    "                      n1 += 1\n",
    "            \n",
    "    for i in range (n_features):\n",
    "        theta[0][i] = math.log((theta[0][i] + alpha)/(n0 + alpha*k))\n",
    "        theta[1][i] = math.log((theta[1][i] + alpha)/(n1 + alpha*k))\n",
    "    #theta[0][j] = (n(c,w) + alpha)/(n(c) + alpha * k)\n",
    "    return theta\n",
    "#print (estimate_log_class_conditional_likelihoods(training_spam, alpha=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f339a9efd8aae50fb2dedbe175cbfdd5",
     "grade": true,
     "grade_id": "cell-851fa744923a9bba",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell. Do not delete or change. \n",
    "# You can use this cell to check whether the returned objects of your function are of the right data type.\n",
    "log_class_conditional_likelihoods = estimate_log_class_conditional_likelihoods(training_spam, alpha=1.0)\n",
    "\n",
    "# Check data type(s)\n",
    "assert(isinstance(log_class_conditional_likelihoods, np.ndarray))\n",
    "\n",
    "# Check shape of numpy array\n",
    "assert(log_class_conditional_likelihoods.shape == (2, 54))\n",
    "\n",
    "# Check data type of array elements\n",
    "assert(log_class_conditional_likelihoods.dtype == float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part  1C: Classify e-mails (10 marks)\n",
    "\n",
    "Having calculated the log class priors and the log class-conditional likelihoods for a given training set, define a function called `predict()`that takes a data set of new messages as input and predicts for each message whether it is spam or not. Note that the input should **not** contain a response variable.\n",
    "\n",
    "Use your `predict()` function to classify the messages of your **training data set** `training_spam`. Compute the accuracy of your algorithm _in the training set_ by comparing your predictions to the true class values. Accuracy is simply defined as the proportion of true predictions made by your classifier. Store the accuracy of your naïve Bayes algorithm in a variable called `training_set_accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a0607f6de9b1318ea89ecf982e1bbaa9",
     "grade": false,
     "grade_id": "cell-28f019cd03547bb7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict(new_data, log_class_priors, log_class_conditional_likelihoods):\n",
    "    \"\"\"\n",
    "    Given a new data set with binary features, predict the corresponding\n",
    "    response for each instance (row) of the new_data set.\n",
    "\n",
    "    :param new_data: a two-dimensional numpy-array with shape = [n_test_samples, n_features].\n",
    "    :param log_class_priors: a numpy array of length 2.\n",
    "    :param log_class_conditional_likelihoods: a numpy array of shape = [2, n_features].\n",
    "        theta[j, i] corresponds to the logarithm of the probability of feature i appearing\n",
    "        in a sample belonging to class j.\n",
    "    :return class_predictions: a numpy array containing the class predictions for each row\n",
    "        of new_data.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE...\n",
    "    class_predictions = np.zeros(new_data.shape[0])\n",
    "    #print(new_data.shape[0], new_data.shape[1])\n",
    "    for i in range(len(new_data)):\n",
    "            # prob message is spam * spam prior/ prob message is ham * ham prior\n",
    "        Pmesspam = 0\n",
    "        Pmesham = 0\n",
    "        for j in range(len(new_data[1])):\n",
    "            if new_data[i][j] == 1:\n",
    "                Pmesspam = Pmesspam + log_class_conditional_likelihoods[1][j]\n",
    "        for j in range(len(new_data[1])):\n",
    "            if new_data[i][j] == 0:\n",
    "                Pmesham = Pmesham + log_class_conditional_likelihoods[0][j]\n",
    "                \n",
    "        Pmesspam = (Pmesspam + log_class_priors[1])/((Pmesspam + log_class_priors[1]) + (Pmesham + log_class_priors[0] ))\n",
    "        Pmesham = (Pmesham + log_class_priors[0])/((Pmesspam + log_class_priors[1]) + (Pmesham + log_class_priors[0] ))\n",
    "        \n",
    "        if Pmesspam >= Pmesham:\n",
    "            class_predictions[i] = 1\n",
    "        else:\n",
    "            class_predictions[i] = 0\n",
    "\n",
    "    return class_predictions\n",
    "\n",
    "def accuracy(y_predictions, y_true):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy.\n",
    "    \n",
    "    :param y_predictions: a one-dimensional numpy array of predicted classes (0s and 1s).\n",
    "    :param y_true: a one-dimensional numpy array of true classes (0s and 1s).\n",
    "    \n",
    "    :return acc: a float between 0 and 1 \n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE...\n",
    "     \n",
    "    correct = 0\n",
    "    for x in range(len(y_predictions)):\n",
    "        if y_predictions[x] == y_true[x]:\n",
    "            correct += 1.0\n",
    "    acc = (correct/(len(y_predictions)))\n",
    "    \n",
    "    return acc\n",
    "# predict(training_spam[:, 1:], log_class_priors, log_class_conditional_likelihoods)\n",
    "# true_classes = training_spam[:, 0]\n",
    "# class_predictions = predict(training_spam[:, 1:], log_class_priors, log_class_conditional_likelihoods)\n",
    "# accuracy(class_predictions, true_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e2352476945f08f15e42cb0e94c070ad",
     "grade": true,
     "grade_id": "cell-4c8adaa150209180",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell. Do not delete or change. \n",
    "# You can use this cell to check whether the returned objects of your function are of the right data type.\n",
    "class_predictions = predict(training_spam[:, 1:], log_class_priors, log_class_conditional_likelihoods)\n",
    "\n",
    "# Check data type(s)\n",
    "assert(isinstance(class_predictions, np.ndarray))\n",
    "\n",
    "# Check shape of numpy array\n",
    "assert(class_predictions.shape == (1000,))\n",
    "\n",
    "# Check data type of array elements\n",
    "assert(np.all(np.logical_or(class_predictions == 0, class_predictions == 1)))\n",
    "       \n",
    "# Check accuracy function\n",
    "true_classes = training_spam[:, 0]\n",
    "training_set_accuracy = accuracy(class_predictions, true_classes)\n",
    "assert(isinstance(training_set_accuracy, float))\n",
    "assert(0 <= training_set_accuracy <= 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1D: Classifying previously unseen data (10 marks).\n",
    "The following cell loads a new set of 500 messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the testing spam data set: (500, 55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 1., 1., 1.],\n",
       "       [1., 1., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\")\n",
    "print(\"Shape of the testing spam data set:\", testing_spam.shape)\n",
    "testing_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the naïve Bayes algorithm that you trained on `training_spam` in order to classify all messages in the `testing_spam` data set. Store the resulting accuracy in a variable called `testing_set_accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "20ca424a81250cfca53ffa68c90a303d",
     "grade": false,
     "grade_id": "cell-fc141a44a0e708b1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class_predictions = predict(testing_spam[:, 1:], log_class_priors, log_class_conditional_likelihoods)\n",
    "true_classes = training_spam[:, 0]\n",
    "testing_set_accuracy = accuracy(class_predictions, true_classes)\n",
    "#print(testing_set_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d89ad23b0827be47fd700442b2b7495c",
     "grade": true,
     "grade_id": "cell-e8b67052cb121115",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell. Do not delete or change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1E: Discussion (5 marks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "76ad4c938cfef7436ef6bc16eb732a8b",
     "grade": true,
     "grade_id": "cell-3e35b05a08d8d3af",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "In 3 sentences or less: Compare the accuracy of your classifier on the training set and on the test set. Are they different? If yes, how do you explain the difference?\n",
    "\n",
    "The accuracy of the classifier on the training set came out to be 61% whereas it came out to be 57% on the testing set. This means that it has been less effective on the testing set. This may be due to the classifier underfitting the dataset since it does not seem to be presenting a very accurate relationship between the input data and the predicted output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 2: Zero or One? (55 marks)\n",
    "\n",
    "In this part of the coursework, you will develop a classifier for a different problem. All you will be given about this problem is a training data set. Your objective is to develop a classifier that will have the highest accuracy in unseen examples.\n",
    "\n",
    "The following cell loads the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data set: (5000, 39)\n",
      "[[0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 1. 0.]\n",
      " [1. 1. 1. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      " [1. 0. 1. ... 0. 1. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_data = np.loadtxt(open(\"data/training_data_part_2.csv\"), delimiter=\",\")\n",
    "print(\"Shape of the training data set:\", training_data.shape)\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is again the response variable. The remaining 38 columns are binary features. You have multiple tasks:\n",
    "\n",
    "(1) Your first task is to write a function called `train()` that takes `training_data` as input and returns all the fitted parameters of your model. Note that the fitted parameters of your model depend on the model you choose. For example, if you use a naïve Bayes classifier, you could return a list of class priors and conditional likelihoods. (This function will allow us to compute your model on the fly. We should be able to execute it in less than 10 minutes.) \n",
    "\n",
    "(2) Your second task is to provide a variable called `fitted_model` which stores the model parameters you found by executing your train() function on the training_data. If your train function takes more than 20 seconds to run, this variable should load precomputed parameter values (possibly from a file) rather than execute the train() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "98502b22b7569c3888bbea2dae89e8a6",
     "grade": false,
     "grade_id": "cell-9284ab8e9721ffc2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "def train(training_data):\n",
    "    \"\"\"\n",
    "    Train a model on the training_data\n",
    "\n",
    "    :param training_data: a two-dimensional numpy-array with shape = [5000, 39] \n",
    "    \n",
    "    :return fitted_model: any data structure that captures your model\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE...\n",
    "    ## Bayes classification\n",
    "    #log_class_priors = estimate_log_class_priors(training_data)\n",
    "    #log_class_conditional_likelihoods = estimate_log_class_conditional_likelihoods(training_data, alpha=1.0)\n",
    "\n",
    "    #fitted_model = {}\n",
    "    #for x in range (2):\n",
    "    #    fitted_model[log_class_priors[x]] = log_class_conditional_likelihoods[x]\n",
    "    \n",
    "    ## SVM classifier \n",
    "    \n",
    "    classifier = svm.SVC(gamma=0.001, C=100.)\n",
    "    classifier.fit(training_data[:, 1:], training_data[:, 0])\n",
    "\n",
    "    return classifier\n",
    "\n",
    "## Uncomment one of the following two lines depending on whether you want us to compute your model on the \n",
    "## fly or load a supplementary file.\n",
    "\n",
    "fitted_model = train(training_data)\n",
    "# fitted_model = load(local_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Your third task is to provide a function called `test()` that uses your `fitted_model` to classify the observations of `testing_data`. The `testing_data` is hidden and may contain any number of observations (rows). It contains 38 columns that have the same structure as the features of `training_data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8547b4673b0548ddd786722f367268a4",
     "grade": false,
     "grade_id": "cell-b62974b058e95e23",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67, 0.708, 0.796, 0.796, 0.808, 0.828, 0.822, 0.828, 0.822, 0.834, 0.834, 0.836, 0.838, 0.84, 0.846, 0.848, 0.842, 0.846, 0.852, 0.84, 0.834, 0.834, 0.838, 0.836, 0.834, 0.832, 0.838, 0.832, 0.834, 0.834, 0.838, 0.842, 0.832, 0.834, 0.836, 0.836, 0.836, 0.836, 0.84, 0.838, 0.834, 0.834, 0.834, 0.838, 0.838, 0.84, 0.836, 0.838, 0.838, 0.836, 0.834, 0.834, 0.844, 0.84, 0.844, 0.848, 0.844, 0.846, 0.846, 0.848, 0.848, 0.848, 0.848, 0.85, 0.846, 0.846, 0.844, 0.842, 0.842, 0.848, 0.848, 0.846, 0.846, 0.848, 0.848, 0.844, 0.85, 0.848, 0.85, 0.852, 0.852, 0.848, 0.85, 0.85, 0.848, 0.848, 0.85, 0.848, 0.848, 0.848, 0.848, 0.85, 0.854, 0.85, 0.852, 0.852, 0.852, 0.852, 0.848]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test(testing_data, fitted_model):\n",
    "    \"\"\"\n",
    "    Classify the rows of testing_data using a fitted_model. \n",
    "\n",
    "    :param testing_data: a two-dimensional numpy-array with shape = [n_test_samples, 38]\n",
    "    :param fitted_model: the output of your train function.\n",
    "\n",
    "    :return class_predictions: a numpy array containing the class predictions for each row\n",
    "        of testing_data.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE...\n",
    "    \n",
    "    ## Bayes classifier\n",
    "    #log_class_priors = fitted_model.keys()\n",
    "    #     for i in range (2):\n",
    "    #         log_class_conditional_likelihoods[i][:] = fitted_model[log_class_priors[i]]\n",
    " \n",
    "    #class_predictions = predict(testing_data[:, 1:], log_class_priors, log_class_conditional_likelihoods)\n",
    "    \n",
    "    ## SVM classifier\n",
    "    classifier = fitted_model\n",
    "    predicted = (classifier.predict(testing_data[:, 0:]))\n",
    "\n",
    "    class_predictions = predicted\n",
    "    return class_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8e632be3b415f26b688aaf8da8354865",
     "grade": true,
     "grade_id": "cell-d6503e588628ad10",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell. Do not delete or change. \n",
    "# You can use this cell to check whether the returned objects of your function are of the right data type.\n",
    "\n",
    "# Test data types if input are the first 20 rows of the training_data.\n",
    "class_predictions = test(training_data[:20, 1:], fitted_model)\n",
    "\n",
    "# Check data type(s)\n",
    "assert(isinstance(class_predictions, np.ndarray))\n",
    "\n",
    "# Check shape of numpy array\n",
    "assert(class_predictions.shape == (20,))\n",
    "\n",
    "# Check data type of array elements\n",
    "assert(np.all(np.logical_or(class_predictions == 0, class_predictions == 1)))\n"
   ]
  },
  {
   "attachments": {
    "accuracy.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4c72e9d23d320745c0b4971d557c7ab3",
     "grade": true,
     "grade_id": "cell-1d336f7ffecd8f71",
     "locked": false,
     "points": 55,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Describe in less than 10 sentences: Explain your classifier. Comment on its performance. What other alternative classifiers did you consider or experiment with? How does the performance of your classifier change as the size of the training set increases? You may want to include figures. \n",
    "\n",
    "For my classifier, I have used support vector machines, using the scikit-learn library, which are supervised learning models\n",
    "and algorithms that are able to analyze and classify data. I have chosen to use the support vector classifier (SVC). By providing the model with training examples, where each training data is labeled as a class, 0 or 1, an SVM training algorithm builds a model which is then able to assign labels to new data. The SVM model that is created represents all of the data as\n",
    "points within the model and they are mapped such that data belonging to different classes is seperated by a wide gap. It \n",
    "classifies new data by mapping it into model and assigning the data to a class dependant on which side of the model\n",
    "the data point lands in.\n",
    "The classifier performs well and gives an 85% accuracy when testing it on the training_spam and testing_spam datasets. \n",
    "I also used the Naive Bayes classifier at first, this has been commented out within train and test cells and is still usable. However, I wanted to try and use the SVC classifier since it didn't look too hard to implement especially when using the scikit-learn library and I was also able to learn how it worked this way. \n",
    "\n",
    "The graph below shows how the performance of the classifier changes when varying the training set, this is performed using training_spam and testing_spam datasets.\n",
    "\n",
    "![accuracy.png](attachment:accuracy.png)\n",
    "\n",
    "\n",
    "<img src=\"images/accuracy.png\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23944593be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67, 0.708, 0.796, 0.796, 0.808, 0.828, 0.822, 0.828, 0.822, 0.834, 0.834, 0.836, 0.838, 0.84, 0.846, 0.848, 0.842, 0.846, 0.852, 0.84, 0.834, 0.834, 0.838, 0.836, 0.834, 0.832, 0.838, 0.832, 0.834, 0.834, 0.838, 0.842, 0.832, 0.834, 0.836, 0.836, 0.836, 0.836, 0.84, 0.838, 0.834, 0.834, 0.834, 0.838, 0.838, 0.84, 0.836, 0.838, 0.838, 0.836, 0.834, 0.834, 0.844, 0.84, 0.844, 0.848, 0.844, 0.846, 0.846, 0.848, 0.848, 0.848, 0.848, 0.85, 0.846, 0.846, 0.844, 0.842, 0.842, 0.848, 0.848, 0.846, 0.846, 0.848, 0.848, 0.844, 0.85, 0.848, 0.85, 0.852, 0.852, 0.848, 0.85, 0.85, 0.848, 0.848, 0.85, 0.848, 0.848, 0.848, 0.848, 0.85, 0.854, 0.85, 0.852, 0.852, 0.852, 0.852, 0.848]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = []\n",
    "testing_set_accuracies = []\n",
    "for i in range (10, training_spam.shape[0], 10):\n",
    "    x.append(i)\n",
    "    fitted_model_test = train(training_spam[:i,:])\n",
    "    class_predictions = test(testing_spam[:, 1:], fitted_model_test)\n",
    "    true_classes = testing_spam[:, 0]\n",
    "    testing_set_accuracies.append(accuracy(class_predictions, true_classes))\n",
    "    \n",
    "plt.xlabel('set size')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(x, testing_set_accuracies, 'r', label = 'Classifier Performance')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print (testing_set_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
